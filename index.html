<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="generator" content="scholpandoc">
  <meta name="viewport" content="width=device-width">
  
  <title>Bas Peters</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.7.1/modernizr.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.js"></script>
  <link rel="stylesheet" href="https://slimgroup.slim.gatech.edu/ScholMD/standalone/slimweb-scholmd-standalone-v0.1-latest.min.css">
</head>
<body>
<div class="scholmd-container">
<div class="scholmd-main">
<div class="math scholmd-math-definitions" style="visibility: hidden; height: 0px; width 0px;">\[
\def\bb{\mathbf b}
\def\bc{\mathbf c}
\defd{\mathbf d}
\def\bg{\mathbf g}
\def\bh{\mathbf h}
\def\bl{\mathbf l}
\defm{\mathbf m}
\def\bp{\mathbf p}
\def\bq{\mathbf q}
\def\br{\mathbf r}
\def\bs{\mathbf s}
\def\bu{\mathbf u}
\defv{\mathbf v}
\def\bw{\mathbf w}
\defy{\mathbf y}
\defx{\mathbf x}
\def\bz{\mathbf z}
%\def\argmin{\operatornamewithlimits{arg min}}
\def\argmin{\mathop{\rm arg\min}}
\def\Ttheta{\boldsymbol\theta}
\def\bb{\mathbf b}
\def\TC{\mathbf C}
\def\TD{\mathbf D}
\def\TK{\mathbf K}
\def\TI{\mathbf I}
\def\bw{\mathbf w}
\def\by{\mathbf y}
\def\TY{\mathbf Y}
\def\TP{\mathbf P}
\def\TS{\mathbf S}
\def\bs{\mathbf s}
\def\bc{\mathbf c}
\def\TW{\mathbf W}
\def\TV{\mathbf V}
\def\TX{\mathbf X}
\def\TQ{\mathbf Q}
\]</div>
<div class="scholmd-content">
<header>
<h1 class="scholmd-title">Bas Peters</h1>
</header>
<p>PhD, University of British Columbia (2019)<br />MSc and BSc, Utrecht University, The Netherlands<br /><a href="https://www.linkedin.com/in/bas-peters-b26ba3a/">LinkedIn</a> | <a href="https://scholar.google.ca/citations?user=gPVDmBEAAAAJ&amp;hl=en&amp;oi=ao">Google Scholar</a> | <a href="https://github.com/PetersBas">GitHub</a></p>
<p>Hi! I currently work for <a href="http://www.compgeoinc.com">Computational Geosciences Inc.</a> where I research <em>i</em>) computational methods to design and train neural networks for large scale inputs; <em>ii</em>) Networks, loss functions, and regularization of deep networks for vision tasks in the earth sciences. Previously, I was a graduate student in the <a href="http://slim.gatech.edu">SLIM</a> group at UBC (currently at Georgia Tech).</p>
<figure class="scholmd-float scholmd-table-float" id="interests">
<div class="scholmd-float-content"><table>
<thead>
<tr class="header">
<th style="text-align: left;">Research projects</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a href="#compnet">Computational methods and design of deep neural networks</a></td>
<td style="text-align: left;"><a href="#compvisgeo">Computer vision for geoscience applications</a></td>
</tr>
<tr class="even">
<td style="text-align: left;"><a href="#constopt">Constrained optimization for regularizing imaging inverse problems</a></td>
<td style="text-align: left;"><a href="#soft">Software</a></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="#numlinalg">Numerical linear algebra and PDE-constrained optimization</a></td>
<td style="text-align: left;"><a href="#apps">Assorted applications</a></td>
</tr>
</tbody>
</table></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Table</span><span class="scholmd-caption-head-label">1</span></span></figcaption></div>
</figure>
<h2 id="publications">Publications</h2>
<p>Please see my <a href="https://scholar.google.ca/citations?user=gPVDmBEAAAAJ&amp;hl=en&amp;oi=ao">scholar page.</a></p>
<h2 id="recent-presentations-2019">Recent presentations (2019)</h2>
<h3 id="upcoming">Upcoming:</h3>
<ul>
<li>Nothing scheduled at the moment.</li>
</ul>
<h3 id="past">Past:</h3>
<ul>
<li>Scientific Computing, Applied and Industrial Mathematics (SCAIM) Seminar Series, UBC, October 29 2019 <a href="https://www.slideshare.net/BasPeters11/learning-from-a-few-largescale-partial-examples-computational-tools-regularization-and-network-design?qid=63f82a0e-9ee2-4a61-8cbb-94cb844e9a00&amp;v=&amp;b=&amp;from_search=1">slides</a></li>
<li>Does shallow geological knowledge help neural-networks to predict deep units? [Society of Exploration Geophysicists, Annual meeting 2019]</li>
<li>A numerical solver for least-squares sub-problems in 3D wavefield reconstruction inversion and related problem formulations [Society of Exploration Geophysicists, Annual meeting 2019]</li>
<li>Automatic classification of geologic units in seismic images using partially interpreted examples [81st EAGE Conference and Exhibition 2019]</li>
<li>Generalized Minkowski sets for the regularization of inverse problems (SIAM Conference on Mathematical and Computational Issues in the Geosciences, 2019) <a href="https://www.pathlms.com/siam/courses/11267/sections/14618/video_presentations/128671">video</a> <a href="https://cdn.fs.pathlms.com/WpyqzDxDQmazQeMb3KRu">slides</a></li>
<li>Networks, loss-functions, regularization, and software for machine learning in the geosciences [Machine learning in solid earth geoscience, hosted by Los Alamos National Laboratory in Santa Fe, 2019]</li>
</ul>
<h2 id="compnet">Computational methods and design of deep neural networks</h2>
<p>Collaborators: Keegan Lensink &amp; Eldad Haber. Research focusses on developing new networks that require less memory for weights and for network states while computing gradients of loss functions.</p>
<figure class="scholmd-float scholmd-figure" id="fig:hypernet">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 40%">
<img src="Figures/Video/Wnet_forward.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 50%">
<img src="Figures/Video/NetworkMemory3D.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">1</span></span><span class="scholmd-caption-text">Overview of the design of HyperNet. Memory consumption of various networks on the right.</span></figcaption></div>
</figure>
<p>The core of hypernet is a leapfrog discretization of a nonlinear telegraph equation, so the forward reads 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation*}
\TY{j+1} = 2 \TW_j\TY_j -  \TW_{j-1} \TY_{j-1} +  f( \TW_j \TY_j,\TK_j),
\end{equation*}
\]</span>
 where <span class="math scholmd-math-inline">\(\TY_j\)</span> are network states at layer <span class="math scholmd-math-inline">\(j\)</span>; <span class="math scholmd-math-inline">\(\TK_j\)</span> represents the weights; <span class="math scholmd-math-inline">\(f(\cdot)\)</span> is a nonlinear function. The essential innovation in this network structure is the use of an orthogonal wavelet transform, <span class="math scholmd-math-inline">\(\TW_j\)</span> to simultaneously change the number of channels and resolution. As a result, we can fully reverse the network using 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation*}
\TY_j = \TW_j^{-1} \bigg[ 2 \TW_{j+1} \TY_{j+1} - h^2 \TK_{j+2}^\top  f ( \TK_{j+2} \TW_{j+1} \TY_{j+1}  ) - \TY_{j+2} \bigg].
\end{equation*}
\]</span>
 Note that <span class="math scholmd-math-inline">\(\TW_j\)</span> is the identity if we do not change resolution/channels. Full reversibility allows us to recompute the states during backpropagation so we do not need to store all states; something that standard implementations of reverse-mode automatic differentation need to do for gradient computations.</p>
<p><a href="https://arxiv.org/pdf/1905.10484">Fully Hyperbolic Convolutional Neural Networks</a></p>
<h2 id="compvisgeo">Deep-learning based computer vision for geoscience applications</h2>
<p>Collaborators: Eldad Haber &amp; Justin Granek. For this project we develop methods to be able to apply deep neural-networks to geoscience problems. We worked on techniques to deal with <em>i)</em> data with sparse labels <em>ii)</em> including prior knowledge via regularization of the output of a network while training, in order to mitigate a lack of labels.</p>
<figure class="scholmd-float scholmd-figure" id="fig:seismic">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 33%">
<img src="Figures/Seismic/Figure2a.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 33%">
<img src="Figures/Seismic/Figure2c.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 33%">
<img src="Figures/Seismic/Figure4.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">2</span></span><span class="scholmd-caption-text">Semantic segmentation of seismic images into lithological units of interest. Training data are slices from a 3D volume. There are 24 training images that each have 2 associated boreholes. This result uses regularization of the network output to mitigate the lack of labeled data.</span></figcaption></div>
</figure>
<p><a href="http://www.earthdoc.org/publication/publicationdetails/?publication=97269">Automatic Classification of Geologic Units in Seismic Images Using Partially Interpreted Examples</a> / <a href="https://arxiv.org/pdf/1901.03786">arXiv</a></p>
<p><a href="https://library.seg.org/doi/10.1190/tle38070534.1">Neural-networks for geophysicists and their application to seismic data interpretation</a> / <a href="https://arxiv.org/pdf/1903.11215">arXiv</a></p>
<p><a href="https://library.seg.org/doi/10.1190/segam2019-3216640.1">Does shallow geological knowledge help neural-networks to predict deep units?</a> / <a href="https://arxiv.org/pdf/1904.04413">arXiv</a></p>
<figure class="scholmd-float scholmd-figure" id="fig:seismichorizon">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 100%">
<img src="Figures/SeismicHorizon/Figure11.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">3</span></span><span class="scholmd-caption-text">Detecting horizons (interfaces) of interest in seismic images. There are a number of training images and each has a few labels (seed points). Our method performs better than methods not based on learning, especially in areas where there are large gaps in the labels.</span></figcaption></div>
</figure>
<p><a href="https://library.seg.org/doi/10.1190/INT-2018-0225.1">Multiresolution neural networks for tracking seismic horizons from few training images</a> / <a href="https://arxiv.org/pdf/1812.11092">arXiv</a></p>
<h2 id="constopt">Constrained optimization for regularizing imaging inverse problems</h2>
<p>Collaborator: Felix J. Herrmann.</p>
<p>We incorporate prior knowledge into the inverse problems via a projection of a vector <span class="math scholmd-math-inline">\(m\)</span> onto an intersection of <span class="math scholmd-math-inline">\(p\)</span> convex and non-convex sets, 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation*}
\min_{x} \frac{1}{2} \| x - m \|_2^2 + \sum_{i=1}^{p} \iota_{\mathcal{C}_i}(A_i x).
\end{equation*}
\]</span>
 Each sets may include a different linear operator <span class="math scholmd-math-inline">\(A_i\)</span>, such as discrete derivative matrices, Fourier/DCT/wavelet/curvelet transforms. We denote the set-indicator function as <span class="math scholmd-math-inline">\(\iota_{\mathcal{C}_i}\)</span>. The projection approach has the advantage that each sets is defined independently of all others; no trade-off/balancing parameters are required. Julia software is available as the <a href="https://petersbas.github.io/SetIntersectionProjectionDocs/">SetIntersectionProjection</a> package.</p>
<figure class="scholmd-float scholmd-figure" id="fig:inpainting">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 70%">
<img src="Figures/SIP/deblurring_inpainting_results2.jpg" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">4</span></span><span class="scholmd-caption-text">Reconstructing images from noisy, blurred, and missing pixels. Shows basis-pursuit denoise using wavelets, versus our method (PARSDMM): projection onto an intersection of constraint sets that were learned from examples.</span></figcaption></div>
</figure>
<ul>
<li><a href="https://arxiv.org/pdf/1902.09699">Algorithms and software for projections onto intersections of convex and non-convex sets with applications to inverse problems (preprint)</a></li>
<li><a href="https://library.seg.org/doi/abs/10.1190/geo2018-0192.1">Projection methods and applications for seismic nonlinear inverse problems with multiple constraints</a></li>
<li><a href="https://library.seg.org/doi/abs/10.1190/tle36010094.1">Constraints versus penalties for edge-preserving full-waveform inversion</a> / <a href="https://www.slim.eos.ubc.ca/Publications/Public/Journals/TheLeadingEdge/2016/peters2016cvp/peters2016cvp.pdf">preprint</a></li>
<li><a href="http://www.earthdoc.org/publication/publicationdetails/?publication=80659">Constrained Waveform Inversion of Colocated VSP and Surface Seismic Data</a> / <a href="https://www.slim.eos.ubc.ca/Publications/Public/Conferences/EAGE/2015/smithyman2015EAGEcwi/smithyman2015EAGEcwi.pdf">preprint</a></li>
</ul>
<p>In case it is difficult to describe a model/image using a set or intersection of sets as above, we can use an additive model. Therefore, we introduced a generalization of the Minkowski set as 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation*}
\mathcal{M} \equiv \{ m = u + v \: | \: u \in \bigcap_{i=1}^p \mathcal{D}_i, \: v \in \bigcap_{j=1}^q \mathcal{E}_j, \: m \in \bigcap_{k=1}^r \mathcal{F}_k \}.
\end{equation*}
\]</span>
 This set allows us to construct a ‘complicated’ model/image from two ‘simple’ ones. We can add multiple pieces of prior knowledge about each component, <span class="math scholmd-math-inline">\(u\)</span> and <span class="math scholmd-math-inline">\(v\)</span>, as well an multiple constraints on their sum. In spirit, this approach generalized ideas from cartoon-texture decomposition, robust prinipal component analysis, and morphological component analysis. Julia software is available to set up constraints sets and compute the <a href="https://petersbas.github.io/GeneralizedMinkowskiSetDocs/">projection onto the Generalized Minkowski Set</a>.</p>
<figure class="scholmd-float scholmd-figure" id="fig:escalator">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 70%">
<img src="Figures/VideoEscalator/escalator_decomposition.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">5</span></span><span class="scholmd-caption-text">Segmentation of a greyscale video as the projection of the entire original video onto a generalized Minkowski set. Each of the components contain either a background or anomaly (moving people).</span></figcaption></div>
</figure>
<p><a href="https://arxiv.org/pdf/1903.03942">Generalized Minkowski sets for the regularization of inverse problems (preprint)</a></p>
<h2 id="soft">Software</h2>
<p><a href="https://petersbas.github.io/SetIntersectionProjectionDocs/">SetIntersectionProjection</a></p>
<ul>
<li>Julia 1.1, uses worker parallelism and multithreading</li>
<li>Simple way of setting up constraints. Software will provide a projector onto the intersection</li>
<li>Use projector for any suitable optimization problem</li>
<li>Contains example of full-waveform inversion, image inpainting/deblurring/denoising, image desaturation</li>
<li>Tested for computational domains of up to <span class="math scholmd-math-inline">\(400^3\)</span></li>
</ul>
<p><br /><a href="https://petersbas.github.io/GeneralizedMinkowskiSetDocs/">Generalized Minkowski Set projections</a></p>
<ul>
<li>This is an extension of SetIntersectionProjection</li>
<li>Build ‘complicated’ models from simple ones, via the addition and intersection of constraint sets</li>
<li>Software will provide a projector onto the Generalized Minkowski set</li>
<li>Contains examples of seismic full-waveform inversion and video segmentation.</li>
</ul>
<h2 id="numlinalg">Numerical linear algebra and PDE-constrained optimization</h2>
<p>Collaborators: Felix J. Herrmann &amp; Tristan van Leeuwen Under Construction</p>
<h2 id="apps">Assorted applications</h2>
<figure class="scholmd-float scholmd-figure" id="fig:videosegmentation">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 40%">
<img src="Figures/Video/Label_Bear3D.png" />
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 35%">
<img src="Figures/Video/true_plus_segmentation_bear_xy.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">6</span></span><span class="scholmd-caption-text">Video segmentation of a 4D RGB video in one go. There is only a single video in the entire dataset that has 3 annotated slices. One crossection of the prediction+data is shown on the right. Uses <a href="#compnet">HyperNet</a></span></figcaption></div>
</figure>
<p>.</p>
<div class="references">

</div>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
      processClass: "math"
    },
    TeX: {
        TagSide: "left",
        TagIndent: "1.2em",
        equationNumbers: {
            autoNumber: "AMS"
        },
        Macros: {
            ensuremath: ["#1",1],
            textsf: ["\\mathsf{\\text{#1}}",1],
            texttt: ["\\mathtt{\\text{#1}}",1]
        }
    },
    "HTML-CSS": { 
        scale: 100,
        availableFonts: ["TeX"], 
        preferredFont: "TeX",
        webFont: "TeX",
        imageFont: "TeX",
        EqnChunk: 1000
    }
});
</script>
<script src="https://www.slim.eos.ubc.ca/Publications/Resources/ScholMD/js/slimweb-scholmd-scripts.js"></script>
<script src="https://slimgroup.slim.gatech.edu/MathJax/MathJax.js?config=TeX-AMS_HTML-full" type="text/javascript"></script>
</div>
</body>
</html>
